{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "## Dataset\n",
    "\n",
    "A public dataset from kaggle was used with minor altering in the naming patterns. The original can be found [here](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia)\n",
    "\n",
    "The dataset is split into 3 folders:\n",
    "- `test`\n",
    "- `train`\n",
    "- `val`\n",
    "\n",
    "Each folder is futher split into `normal` and `pneumonia`. There a total of 5863 files stored as JPEGs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Import all required packages and set the base path for the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: ./datasets\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import skimage\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "datasetsPath = \"./datasets\"\n",
    "\n",
    "print(\"Path to dataset files:\", datasetsPath)\n",
    "\n",
    "labels = ['pneumonia', 'normal']\n",
    "image_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data (dir_relative_path):\n",
    "    data = []\n",
    "    for label in labels:\n",
    "        currentPath = os.path.join(datasetsPath, dir_relative_path, label)\n",
    "        print(\"Working inside folder: \", currentPath)\n",
    "        class_number = labels.index(label)\n",
    "\n",
    "        for image in os.listdir(currentPath):\n",
    "            try:\n",
    "                if image.endswith('.DS_Store'):\n",
    "                    continue\n",
    "\n",
    "                image_path = os.path.join(currentPath, image)\n",
    "                image_file = tf.io.read_file(image_path)\n",
    "                \n",
    "                image_arr = tf.image.decode_image(image_file, channels=1)\n",
    "                                \n",
    "                resized_arr = tf.image.resize(image_arr, [image_size, image_size])\n",
    "\n",
    "                data.append([resized_arr, class_number])\n",
    "            except Exception as ex:\n",
    "                print(ex)\n",
    "\n",
    "    return np.array(data, dtype=\"object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dat Augmentation\n",
    "Import the necessary packages and resize the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D,Dropout\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1. / 255, \n",
    "                                    horizontal_flip=True,\n",
    "                                    vertical_flip=False,\n",
    "                                    rotation_range=20, # randomly rotate the image up to 20 degrees\n",
    "                                    shear_range=0.1, # skew the sides of the images by up to 10 degrees \n",
    "                                    width_shift_range=0.2, # shift the images left/right\n",
    "                                    height_shift_range=0.2, # shift the images up/down TBD: needs more testing of values\n",
    "                                    brightness_range=[0.8, 1.2],\n",
    "                                    fill_mode=\"nearest\")\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale= 1. / 255)\n",
    "test_datagen = ImageDataGenerator(rescale= 1. / 255)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\"./datasets/train\",\n",
    "                                  batch_size = 64,\n",
    "                                  target_size=(image_size, image_size),\n",
    "                                  class_mode = \"categorical\",\n",
    "                                  shuffle=True,\n",
    "                                  seed = 42,\n",
    "                                  color_mode= \"rgb\")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\"./datasets/test\",\n",
    "                                  batch_size = 64,\n",
    "                                  target_size=(image_size, image_size),\n",
    "                                  class_mode = \"categorical\",\n",
    "                                  shuffle=True,\n",
    "                                  seed = 42,\n",
    "                                  color_mode= \"rgb\")\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\"./datasets/val\",\n",
    "                                  batch_size = 64,\n",
    "                                  target_size=(image_size, image_size),\n",
    "                                  class_mode = \"categorical\",\n",
    "                                  shuffle=True,\n",
    "                                  seed = 42,\n",
    "                                  color_mode= \"rgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'normal': 0, 'pneumonia': 1}\n",
      "{0: 'normal', 1: 'pneumonia'}\n"
     ]
    }
   ],
   "source": [
    "class_labels = train_generator.class_indices\n",
    "\n",
    "print(class_labels)\n",
    "\n",
    "# Flip them around so we have \"index : value\"\n",
    "class_name = {}\n",
    "\n",
    "for value, index in class_labels.items():\n",
    "    class_name[index] = value\n",
    "\n",
    "print(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4608)              115610112 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1152)              5309568   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 2306      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 140,946,370\n",
      "Trainable params: 120,921,986\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG19(input_shape= (image_size, image_size, 3),\n",
    "      include_top = False,\n",
    "      weights = \"imagenet\")\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "flat = Flatten()(base_model.output)\n",
    "\n",
    "# TODO: test and change around the neuron counts\n",
    "\n",
    "class_1 = Dense(4608, activation= \"relu\")(flat)\n",
    "dropout = Dropout(0.2)(class_1)\n",
    "\n",
    "class_2 = Dense(1152, activation = 'relu')(dropout)\n",
    "output_layer = Dense(2, activation = 'softmax')(class_2)\n",
    "\n",
    "model_01 = Model(base_model.inputs, output_layer)\n",
    "model_01.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointPath = \"./modelCheckpoints/model.keras\"\n",
    "\n",
    "early_stop = EarlyStopping(monitor= \"val_loss\",\n",
    "                   verbose= 1,\n",
    "                   mode= \"min\",\n",
    "                   patience= 4) # TODO: play around with patience\n",
    "\n",
    "checkpoint = ModelCheckpoint(checkpointPath,\n",
    "                monitor= \"val_loss\",\n",
    "                save_best_only=True,\n",
    "                save_weights_only=False,\n",
    "                save_freq= \"epoch\",\n",
    "                mode= \"auto\")\n",
    "\n",
    "# TODO: play around with the values\n",
    "rate_reduction = ReduceLROnPlateau(monitor=\"val_accuracy\",\n",
    "                        patience= 3,\n",
    "                        verbose= 1,\n",
    "                        factor= 0.5, # \"learning rate * factor\" after patience runs out (? correct word ?)\n",
    "                        min_lr= 0.0001)\n",
    "\n",
    "# Stochatic Gradient Descent\n",
    "sgd = SGD(learning_rate= 0.001, # Higher value for training\n",
    "        momentum= 0.5,\n",
    "        nesterov=True)\n",
    "\n",
    "\n",
    "model_01.compile(loss=\"categorical_crossentropy\", optimizer= sgd, metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      " 82/250 [========>.....................] - ETA: 2:02 - loss: 0.4794 - accuracy: 0.7929WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 3750 batches). You may need to use the repeat() function when building your dataset.\n",
      "250/250 [==============================] - 72s 254ms/step - loss: 0.4794 - accuracy: 0.7929 - val_loss: 0.4368 - val_accuracy: 0.7500 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "history_01 = model_01.fit(train_generator, \n",
    "            steps_per_epoch=250,\n",
    "            epochs=15, \n",
    "            callbacks=[early_stop, checkpoint, rate_reduction],\n",
    "            validation_data=valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(\"modelWeights/\"):\n",
    "    os.mkdir(\"modelWeights/\")\n",
    "\n",
    "model_01.save(filepath = \"modelWeights/vgg19_model_01.keras\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 147ms/step - loss: 0.4368 - accuracy: 0.7500\n",
      "10/10 [==============================] - 7s 675ms/step - loss: 0.4136 - accuracy: 0.8333\n"
     ]
    }
   ],
   "source": [
    "model_01.load_weights(\"modelWeights/vgg19_model_01.keras\")\n",
    "\n",
    "vgg_val_eval_01 = model_01.evaluate(valid_generator)\n",
    "vgg_test_eval_01 = model_01.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Validation Loss: {vgg_val_eval_01[0]}\")\n",
    "print(f\"Validation Accuarcy: {vgg_val_eval_01[1]}\")\n",
    "print(f\"Test Loss: {vgg_test_eval_01[0]}\")\n",
    "print(f\"Test Accuarcy: {vgg_test_eval_01[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: research if It's better to copy-paste the previous or just use it like this\n",
    "# Copy-pasting should allow for changing of variables\n",
    "model_02 = Model(base_model.inputs, output_layer)\n",
    "\n",
    "model_02.load_weights(\"modelWeights/vgg19_model_01.keras\")\n",
    "\n",
    "set_trainable = False\n",
    "for layer in base_model.layers:\n",
    "    if layer.name in [ 'block5_conv3','block5_conv4']:\n",
    "        set_trainable=True\n",
    "    else:\n",
    "        set_trainable = False\n",
    "    layer.trainable = set_trainable\n",
    "print(model_02.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochatic Gradient Descent\n",
    "sgd = SGD(learning_rate= 0.0001, # low value for fine tuning\n",
    "        momentum= 0.5,\n",
    "        nesterov=True)\n",
    "\n",
    "model_02.compile(loss=\"categorical_crossentropy\", optimizer= sgd, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_02 = model_02.fit(train_generator, \n",
    "            steps_per_epoch=200,\n",
    "            epochs=10, \n",
    "            callbacks=[early_stop, checkpoint, rate_reduction],\n",
    "            validation_data=valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('modelWeights/'):\n",
    "    os.mkdir(\"modelWeights/\")\n",
    "model_02.save(filepath = \"modelWeights/vgg19_model_02.keras\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_02.load_weights(\"modelWeights/vgg19_model_02.keras\")\n",
    "\n",
    "vgg_val_eval_02 = model_02.evaluate(valid_generator)\n",
    "vgg_test_eval_02 = model_02.evaluate(test_generator)\n",
    "\n",
    "print(f\"Validation Loss: {vgg_val_eval_02[0]}\")\n",
    "print(f\"Validation Accuarcy: {vgg_val_eval_02[1]}\")\n",
    "print(f\"Test Loss: {vgg_test_eval_02[0]}\")\n",
    "print(f\"Test Accuarcy: {vgg_test_eval_02[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tuning the entire network (Second time)\n",
    "\n",
    "base_model = VGG19(include_top=False, input_shape=(image_size, image_size,3))\n",
    "\n",
    "x = base_model.output\n",
    "flat = Flatten()(x)\n",
    "\n",
    "class_1 = Dense(4608, activation = 'relu')(flat)\n",
    "dropout = Dropout(0.2)(class_1)\n",
    "class_2 = Dense(1152, activation = 'relu')(dropout)\n",
    "output = Dense(2, activation = 'softmax')(class_2)\n",
    "\n",
    "model_03 = Model(base_model.inputs, output)\n",
    "model_03.load_weights(\"modelWeights/vgg19_model_02.keras\")\n",
    "\n",
    "print(model_03.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochatic Gradient Descent\n",
    "sgd = SGD(learning_rate= 0.0001, # Low initial value = more gradual updates\n",
    "        momentum= 0.8, # TODO: play around with the momentum\n",
    "        nesterov=True)\n",
    "model_03.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_03 = model_03.fit(train_generator, \n",
    "            steps_per_epoch=100,\n",
    "            epochs=5, \n",
    "            callbacks=[early_stop, checkpoint, rate_reduction],\n",
    "            validation_data=valid_generator)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_val_eval_03 = model_03.evaluate(valid_generator)\n",
    "vgg_test_eval_03 = model_03.evaluate(test_generator)\n",
    "\n",
    "print(f\"Validation Loss: {vgg_val_eval_03[0]}\")\n",
    "print(f\"Validation Accuarcy: {vgg_val_eval_03[1]}\")\n",
    "print(f\"Test Loss: {vgg_test_eval_03[0]}\")\n",
    "print(f\"Test Accuarcy: {vgg_test_eval_03[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('modelWeights/'):\n",
    "    os.mkdir(\"modelWeights/\")\n",
    "model_03.save(filepath = \"modelWeights/vgg_unfrozen.keras\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
